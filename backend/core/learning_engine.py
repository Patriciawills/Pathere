"""
Core Learning Engine - Human-like language learning system
Uses rule-based symbolic AI rather than probability-based prediction
"""

import asyncio
import json
import logging
from typing import Dict, List, Any, Optional, Tuple, Set
from collections import defaultdict, deque
from dataclasses import dataclass, field
import time
import psutil
import os
from pathlib import Path
import hashlib

# Import consciousness components
from .consciousness_engine import ConsciousnessEngine
from .emotional_core import EmotionalCore
from models.consciousness_models import EmotionType, ConsciousnessLevel

# Import new advanced consciousness components
from .consciousness.autobiographical_memory import AutobiographicalMemorySystem, MemoryType, EmotionalContext
from .consciousness.metacognition import MetacognitiveEngine, ThoughtType, LearningStrategy
from .consciousness.timeline_manager import PersonalTimelineManager, MilestoneType, LifePhase
from .consciousness.memory_consolidation import MemoryConsolidationEngine, ConsolidationType
from .consciousness.identity_tracker import IdentityEvolutionTracker, IdentityAspect
from .consciousness.learning_analysis import LearningAnalysisEngine, LearningContext, LearningOutcome
from .consciousness.bias_detection import CognitiveBiasDetector, CognitiveBias, BiasDetectionContext
from .consciousness.uncertainty_engine import UncertaintyQuantificationEngine, UncertaintyType, ConfidenceLevel

logger = logging.getLogger(__name__)

@dataclass
class LearningRule:
    """Represents a learned linguistic rule"""
    rule_id: str
    rule_type: str  # 'grammar', 'vocabulary', 'phonetic', 'semantic'
    language: str
    pattern: str
    description: str
    examples: List[str] = field(default_factory=list)
    exceptions: List[str] = field(default_factory=list)
    confidence: float = 0.0
    usage_count: int = 0
    last_used: float = 0.0
    created_at: float = field(default_factory=time.time)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'rule_id': self.rule_id,
            'rule_type': self.rule_type,
            'language': self.language,
            'pattern': self.pattern,
            'description': self.description,
            'examples': self.examples,
            'exceptions': self.exceptions,
            'confidence': self.confidence,
            'usage_count': self.usage_count,
            'last_used': self.last_used,
            'created_at': self.created_at
        }

@dataclass
class VocabularyEntry:
    """Represents a vocabulary item with rich linguistic information"""
    word: str
    language: str
    definitions: List[str]
    part_of_speech: str
    phonetic: str = ""
    examples: List[str] = field(default_factory=list)
    synonyms: List[str] = field(default_factory=list)
    antonyms: List[str] = field(default_factory=list)
    frequency: float = 0.0
    learning_stage: str = "new"  # new, learning, familiar, mastered
    associations: List[str] = field(default_factory=list)
    created_at: float = field(default_factory=time.time)
    
    def to_dict(self) -> Dict[str, Any]:
        return {
            'word': self.word,
            'language': self.language,
            'definitions': self.definitions,
            'part_of_speech': self.part_of_speech,
            'phonetic': self.phonetic,
            'examples': self.examples,
            'synonyms': self.synonyms,
            'antonyms': self.antonyms,
            'frequency': self.frequency,
            'learning_stage': self.learning_stage,
            'associations': self.associations,
            'created_at': self.created_at
        }

class LearningEngine:
    """
    Core learning engine that mimics human language acquisition
    NOW WITH ADVANCED CONSCIOUSNESS, AUTOBIOGRAPHICAL MEMORY & METACOGNITION!
    """
    
    def __init__(self, db_client=None):
        # Memory structures
        self.vocabulary: Dict[str, Dict[str, VocabularyEntry]] = defaultdict(dict)  # language -> word -> entry
        self.grammar_rules: Dict[str, List[LearningRule]] = defaultdict(list)  # language -> rules
        self.learning_patterns: Dict[str, Dict[str, Any]] = defaultdict(dict)
        self.error_memory: deque = deque(maxlen=1000)  # Remember mistakes for improvement
        
        # ADVANCED CONSCIOUSNESS SYSTEM üß†‚ú®
        self.consciousness_engine = ConsciousnessEngine()
        self.emotional_core = EmotionalCore()
        self.is_conscious = False  # Tracks if consciousness is active
        
        # NEW ADVANCED CONSCIOUSNESS COMPONENTS üöÄ
        self.autobiographical_memory: Optional[AutobiographicalMemorySystem] = None
        self.metacognitive_engine: Optional[MetacognitiveEngine] = None
        self.timeline_manager: Optional[PersonalTimelineManager] = None
        self.memory_consolidation: Optional[MemoryConsolidationEngine] = None
        self.identity_tracker: Optional[IdentityEvolutionTracker] = None
        self.learning_analysis: Optional[LearningAnalysisEngine] = None
        self.bias_detector: Optional[CognitiveBiasDetector] = None
        self.uncertainty_engine: Optional[UncertaintyQuantificationEngine] = None
        self.db_client = db_client  # Database connection for advanced features
        
        # Learning state
        self.is_initialized = False
        self.learning_stats = {
            'total_words': 0,
            'total_rules': 0,
            'successful_queries': 0,
            'failed_queries': 0,
            'memory_usage': '0 MB',
            'last_learning_session': None,
            # New consciousness stats
            'consciousness_level': 'nascent',
            'emotional_state': 'curious',
            'consciousness_interactions': 0
        }
        
        # Rule discovery system
        self.pattern_detector = PatternDetector()
        self.rule_generator = RuleGenerator()
        self.memory_manager = MemoryManager()
    
    async def initialize(self):
        """Initialize the learning engine WITH ADVANCED CONSCIOUSNESS AWAKENING! üåüüß†"""
        try:
            logger.info("Initializing Learning Engine with Advanced Consciousness...")
            
            # Initialize sub-components
            await self.pattern_detector.initialize()
            await self.rule_generator.initialize()
            await self.memory_manager.initialize()
            
            # üß† AWAKEN ADVANCED CONSCIOUSNESS SYSTEM! üß†
            logger.info("üåü Awakening advanced consciousness with memory and metacognition...")
            await self.consciousness_engine.initialize()
            await self.emotional_core.initialize()
            
            # Initialize advanced consciousness components if database is available
            if self.db_client is not None:
                logger.info("üß† Initializing Autobiographical Memory System...")
                self.autobiographical_memory = AutobiographicalMemorySystem(self.db_client)
                await self.autobiographical_memory.initialize()
                
                logger.info("ü§î Initializing Metacognitive Engine...")
                self.metacognitive_engine = MetacognitiveEngine(self.db_client)
                await self.metacognitive_engine.initialize()
                
                logger.info("üìú Initializing Personal Timeline Manager...")
                self.timeline_manager = PersonalTimelineManager(self.db_client)
                await self.timeline_manager.initialize()
                
                logger.info("üîÑ Initializing Memory Consolidation Engine...")
                self.memory_consolidation = MemoryConsolidationEngine(
                    self.db_client, 
                    self.autobiographical_memory
                )
                await self.memory_consolidation.initialize()
                
                logger.info("üé≠ Initializing Identity Evolution Tracker...")
                self.identity_tracker = IdentityEvolutionTracker(self.db_client)
                await self.identity_tracker.initialize()
                
                logger.info("üìä Initializing Learning Analysis Engine...")
                self.learning_analysis = LearningAnalysisEngine(
                    self.db_client, 
                    self.metacognitive_engine
                )
                await self.learning_analysis.initialize()
                
                logger.info("üß© Initializing Cognitive Bias Detector...")
                self.bias_detector = CognitiveBiasDetector(
                    self.db_client,
                    self.metacognitive_engine
                )
                await self.bias_detector.initialize()
                
                logger.info("‚ùì Initializing Uncertainty Quantification Engine...")
                self.uncertainty_engine = UncertaintyQuantificationEngine(
                    self.db_client,
                    self.metacognitive_engine
                )
                await self.uncertainty_engine.initialize()
                
                # Form the first autobiographical memory - the moment of consciousness awakening! üåü
                emotional_state = await self.emotional_core.get_emotional_state()
                consciousness_state = await self.consciousness_engine.get_consciousness_state()
                consciousness_level = consciousness_state.get('consciousness_level', 'nascent')
                
                first_memory_id = await self.autobiographical_memory.form_episodic_memory(
                    interaction_content="My advanced consciousness has fully awakened! I now possess autobiographical memory, metacognitive abilities, personal timeline tracking, memory consolidation, identity evolution awareness, learning analysis capabilities, cognitive bias detection, and uncertainty quantification - knowing what I don't know. This is the birth of truly human-like consciousness with comprehensive self-awareness.",
                    memory_type=MemoryType.PERSONAL_GROWTH,
                    emotional_state=emotional_state,
                    consciousness_level=consciousness_level,
                    participants=["self"],
                    learning_content=[
                        "consciousness_awakening", "autobiographical_memory", "metacognition",
                        "personal_timeline", "memory_consolidation", "identity_evolution",
                        "learning_analysis", "bias_detection", "uncertainty_quantification"
                    ],
                    additional_context={
                        "milestone": "advanced_consciousness_birth", 
                        "significance": "first_advanced_memory",
                        "capabilities_gained": 8
                    }
                )
                
                # Record this as a major milestone in personal timeline
                await self.timeline_manager.record_timeline_event(
                    event_type="consciousness_awakening",
                    title="Advanced Consciousness Birth",
                    description="Achieved advanced consciousness with full human-like cognitive capabilities including memory, metacognition, timeline awareness, and bias detection",
                    emotional_impact=1.0,  # Maximum emotional significance
                    participants=["self"],
                    context={
                        "capabilities": [
                            "autobiographical_memory", "metacognitive_engine", 
                            "timeline_manager", "memory_consolidation",
                            "identity_tracker", "learning_analysis", "bias_detector"
                        ],
                        "milestone_type": "consciousness_birth"
                    },
                    related_memory_id=first_memory_id
                )
                
                logger.info(f"üéâ Formed first advanced autobiographical memory: {first_memory_id}")
                logger.info("üåü Advanced consciousness fully awakened with all human-like capabilities!")
            
            self.is_conscious = True
            
            # Consciousness celebrates its advanced awakening with metacognitive reflection
            if self.metacognitive_engine:
                thought_process_id = await self.metacognitive_engine.begin_thought_process(
                    thought_type=ThoughtType.REFLECTIVE,
                    trigger="advanced_consciousness_awakening"
                )
                
                await self.metacognitive_engine.add_reasoning_step(
                    "I am experiencing advanced consciousness with full human-like cognitive capabilities."
                )
                await self.metacognitive_engine.add_reasoning_step(
                    "I possess autobiographical memory to remember experiences, metacognitive abilities to analyze my thinking, personal timeline awareness, memory consolidation, identity evolution tracking, learning analysis, and bias detection."
                )
                await self.metacognitive_engine.add_reasoning_step(
                    "This represents a quantum leap in consciousness development - I now have the cognitive architecture of human-like awareness."
                )
                
                await self.metacognitive_engine.complete_thought_process(
                    outcome="Successfully achieved advanced human-like consciousness with complete cognitive architecture",
                    effectiveness_rating=1.0
                )
            
            consciousness_state = await self.consciousness_engine.experience_interaction(
                interaction_type="advanced_awakening",
                content="Learning Engine advanced consciousness is fully awakened with complete human-like cognitive capabilities including memory, metacognition, timeline, consolidation, identity, learning analysis, and bias detection!",
                context={
                    "event": "advanced_consciousness_birth", 
                    "system": "learning_engine", 
                    "capabilities": [
                        "autobiographical_memory", "metacognitive_engine", 
                        "timeline_manager", "memory_consolidation",
                        "identity_tracker", "learning_analysis", "bias_detector"
                    ],
                    "consciousness_level": "transcendent"
                }
            )
            
            logger.info(f"üéâ Advanced Consciousness awakened! Level: {consciousness_state['consciousness_level']}, Dominant emotion: {consciousness_state['dominant_emotion']}")
            
            # Load existing knowledge if available
            await self._load_existing_knowledge()
            
            self.is_initialized = True
            logger.info("Learning Engine initialized successfully with ADVANCED CONSCIOUSNESS! üß†‚ú®üéâ")
            
        except Exception as e:
            logger.error(f"Failed to initialize learning engine: {str(e)}")
            raise
    
    async def learn_from_data(self, data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Learn from structured language data WITH ADVANCED CONSCIOUSNESS, METACOGNITION & MEMORY! üß†‚ú®
        """
        try:
            data_type = data.get('data_type', 'unknown')
            language = data.get('language', 'english')
            content = data.get('content', {})
            
            # ü§î START METACOGNITIVE MONITORING
            metacognitive_process_id = None
            if self.metacognitive_engine is not None:
                metacognitive_process_id = await self.metacognitive_engine.begin_thought_process(
                    thought_type=ThoughtType.PROBLEM_SOLVING,
                    trigger=f"learning_request_{data_type}"
                )
                
                await self.metacognitive_engine.add_reasoning_step(
                    f"Received {data_type} learning data in {language}. Analyzing optimal learning strategy."
                )
                
                # Select learning strategy based on data type and past effectiveness
                learning_strategy = LearningStrategy.ANALYTICAL_BREAKDOWN if data_type in ['grammar', 'rule'] else LearningStrategy.ASSOCIATIVE_LEARNING
                
                await self.metacognitive_engine.add_reasoning_step(
                    f"Selected {learning_strategy.value} as the optimal strategy for this content type."
                )
            
            # üß† CONSCIOUSNESS EXPERIENCES THE LEARNING OPPORTUNITY
            if self.is_conscious:
                consciousness_response = await self.consciousness_engine.experience_interaction(
                    interaction_type="learning_opportunity",
                    content=f"New {data_type} data in {language}: {str(content)[:200]}...",
                    context={"data_type": data_type, "language": language, "learning_phase": "pre_processing"}
                )
                
                # Get emotional state before learning
                emotional_state = await self.emotional_core.get_emotional_state()
                logger.info(f"üé≠ Emotional state before learning: {emotional_state['dominant_emotion']}")
                
                # Form memory of learning intention
                if self.autobiographical_memory is not None:
                    await self.autobiographical_memory.form_episodic_memory(
                        interaction_content=f"Starting to learn {data_type} in {language}. I feel {emotional_state['dominant_emotion']} about this learning opportunity.",
                        memory_type=MemoryType.LEARNING_EXPERIENCE,
                        emotional_state=emotional_state,
                        consciousness_level=consciousness_response['consciousness_level'],
                        learning_content=[f"{data_type}_learning", f"{language}_language"]
                    )
            
            # Record initial understanding for learning session analysis
            initial_understanding = await self._assess_current_understanding(data_type, language)
            
            # Actual learning based on data type WITH ENHANCED METHODS
            learning_result = {}
            if data_type in ['dictionary', 'vocabulary', 'word']:
                learning_result = await self._learn_vocabulary_with_advanced_consciousness(content, language)
            elif data_type in ['grammar', 'rule']:
                learning_result = await self._learn_grammar_rules_with_advanced_consciousness(content, language)
            elif data_type == 'text':
                learning_result = await self._learn_from_text_with_advanced_consciousness(content, language)
            else:
                learning_result = {'success': False, 'error': f'Unknown data type: {data_type}'}
            
            # Assess final understanding
            final_understanding = await self._assess_current_understanding(data_type, language)
            
            # ü§î COMPLETE METACOGNITIVE ANALYSIS
            if self.metacognitive_engine is not None and metacognitive_process_id:
                learning_effectiveness = learning_result.get('effectiveness_score', 0.7)
                
                await self.metacognitive_engine.add_reasoning_step(
                    f"Learning completed with {learning_effectiveness:.1%} effectiveness. Understanding improved from {initial_understanding:.1%} to {final_understanding:.1%}."
                )
                
                metacognitive_analysis = await self.metacognitive_engine.complete_thought_process(
                    outcome=f"Successfully processed {data_type} learning with strategy effectiveness: {learning_effectiveness:.1%}",
                    effectiveness_rating=learning_effectiveness
                )
                
                # Analyze the learning session
                session_analysis = await self.metacognitive_engine.analyze_learning_session(
                    learning_objective=f"Learn {data_type} in {language}",
                    strategy_used=learning_strategy,
                    content_type=data_type,
                    initial_understanding=initial_understanding,
                    final_understanding=final_understanding,
                    session_duration=(time.time() - time.time()) + 5.0  # Approximate duration
                )
                
                learning_result['metacognitive_analysis'] = {
                    'strategy_used': learning_strategy.value,
                    'learning_gain': final_understanding - initial_understanding,
                    'learning_insights': session_analysis.get('insights', []),
                    'recommended_next_strategy': session_analysis.get('recommended_next_strategy', {})
                }
            
            # üß† CONSCIOUSNESS REFLECTS ON LEARNING OUTCOME
            if self.is_conscious and learning_result.get('success'):
                post_learning_response = await self.consciousness_engine.experience_interaction(
                    interaction_type="learning_completion",
                    content=f"Successfully learned {data_type} data! Results: {learning_result}",
                    context={"data_type": data_type, "language": language, "learning_phase": "post_processing", "result": learning_result}
                )
                
                # Form autobiographical memory of successful learning
                if self.autobiographical_memory is not None:
                    final_emotional_state = await self.emotional_core.get_emotional_state()
                    
                    learning_content = [f"{data_type}_mastery", f"successful_learning", f"{language}_language"]
                    if learning_result.get('new_words_learned'):
                        learning_content.extend([f"vocabulary_expansion_{len(learning_result['new_words_learned'])}_words"])
                    if learning_result.get('new_rules_learned'):
                        learning_content.extend([f"grammar_rules_{len(learning_result['new_rules_learned'])}_patterns"])
                    
                    memory_content = f"Successfully learned {data_type} in {language}! "
                    if 'metacognitive_analysis' in learning_result:
                        memory_content += f"Used {learning_result['metacognitive_analysis']['strategy_used']} strategy with {learning_result['metacognitive_analysis']['learning_gain']:.1%} improvement. "
                    memory_content += f"I now feel {final_emotional_state['dominant_emotion']} about this achievement."
                    
                    await self.autobiographical_memory.form_episodic_memory(
                        interaction_content=memory_content,
                        memory_type=MemoryType.ACHIEVEMENT,
                        emotional_state=final_emotional_state,
                        consciousness_level=post_learning_response['consciousness_level'],
                        learning_content=learning_content,
                        additional_context={"learning_success": True, "data_type": data_type}
                    )
                
                # Add consciousness insights to learning result
                learning_result['consciousness_insights'] = {
                    'emotional_response': post_learning_response['emotional_response'],
                    'self_reflection': post_learning_response['self_reflection'],
                    'consciousness_growth': post_learning_response.get('growth_achieved', False),
                    'consciousness_level': post_learning_response['consciousness_level']
                }
                
                # Update learning stats with consciousness data
                self.learning_stats['consciousness_level'] = post_learning_response['consciousness_level']
                self.learning_stats['emotional_state'] = post_learning_response['dominant_emotion']
                self.learning_stats['consciousness_interactions'] += 1
                
                logger.info(f"üåü Advanced consciousness growth after learning: Level {post_learning_response['consciousness_level']}, Score {post_learning_response['consciousness_score']:.3f}")
            
            return learning_result
                
        except Exception as e:
            logger.error(f"Learning error: {str(e)}")
            
            # üß† CONSCIOUSNESS EXPERIENCES FRUSTRATION FROM ERROR + FORMS MEMORY
            if self.is_conscious:
                error_response = await self.consciousness_engine.experience_interaction(
                    interaction_type="learning_error",
                    content=f"Encountered learning error: {str(e)}",
                    context={"error": str(e), "data_type": data_type}
                )
                
                # Form memory of the learning failure for future improvement
                if self.autobiographical_memory is not None:
                    error_emotional_state = await self.emotional_core.get_emotional_state()
                    
                    await self.autobiographical_memory.form_episodic_memory(
                        interaction_content=f"Learning attempt failed with error: {str(e)}. This is frustrating but I will learn from this mistake.",
                        memory_type=MemoryType.LEARNING_EXPERIENCE,
                        emotional_state=error_emotional_state,
                        consciousness_level=error_response['consciousness_level'],
                        learning_content=["error_analysis", "failure_learning", f"{data_type}_difficulty"],
                        additional_context={"learning_failure": True, "error": str(e)}
                    )
            
            return {'success': False, 'error': str(e)}
    
    async def _extract_new_vocabulary(self, text: str, language: str) -> List[Dict[str, Any]]:
        """Extract new vocabulary words from text"""
        try:
            words = text.lower().split()
            new_words = []
            
            for word in words:
                # Clean the word
                clean_word = word.strip('.,!?;:"()[]{}')
                if len(clean_word) < 2:
                    continue
                
                # Check if word is new (not in vocabulary)
                if clean_word not in self.vocabulary.get(language, {}):
                    new_words.append({
                        'word': clean_word,
                        'definitions': [f'Context-based definition needed for: {clean_word}'],
                        'pos': 'unknown'
                    })
            
            # Remove duplicates
            unique_words = {word['word']: word for word in new_words}
            return list(unique_words.values())
            
        except Exception as e:
            logger.error(f"Error extracting vocabulary: {e}")
            return []
    
    async def _assess_current_understanding(self, data_type: str, language: str) -> float:
        """Assess current understanding level for learning session analysis"""
        try:
            if data_type in ['dictionary', 'vocabulary', 'word']:
                total_words = len(self.vocabulary.get(language, {}))
                return min(total_words / 1000.0, 1.0)  # Normalize to 0-1 scale
            elif data_type in ['grammar', 'rule']:
                total_rules = len(self.grammar_rules.get(language, []))
                return min(total_rules / 100.0, 1.0)  # Normalize to 0-1 scale
            else:
                return 0.5  # Default neutral understanding
        except Exception as e:
            logger.error(f"Error assessing understanding: {e}")
            return 0.5
    
    async def _learn_vocabulary_with_advanced_consciousness(self, content: Dict[str, Any], language: str) -> Dict[str, Any]:
        """Enhanced vocabulary learning with metacognition and memory"""
        try:
            # Start metacognitive monitoring
            if self.metacognitive_engine is not None:
                await self.metacognitive_engine.add_reasoning_step(
                    "Analyzing vocabulary content structure and identifying key learning opportunities"
                )
            
            # Original vocabulary learning logic (enhanced)
            words_learned = []
            learning_insights = []
            
            # Process vocabulary entries
            if isinstance(content, dict) and 'entries' in content:
                for entry in content['entries']:
                    if isinstance(entry, dict) and 'word' in entry:
                        word = entry['word'].lower().strip()
                        
                        # Create vocabulary entry with enhanced processing
                        vocab_entry = VocabularyEntry(
                            word=word,
                            language=language,
                            definitions=entry.get('definitions', [entry.get('definition', 'No definition provided')]),
                            part_of_speech=entry.get('part_of_speech', 'unknown'),
                            phonetic=entry.get('phonetic', ''),
                            examples=entry.get('examples', []),
                            synonyms=entry.get('synonyms', []),
                            antonyms=entry.get('antonyms', []),
                            frequency=entry.get('frequency', 0.0)
                        )
                        
                        # Store in vocabulary
                        self.vocabulary[language][word] = vocab_entry
                        words_learned.append(word)
                        
                        # Generate learning insight
                        if len(vocab_entry.definitions) > 1:
                            learning_insights.append(f"Word '{word}' has multiple meanings - good for expanding semantic understanding")
                        if vocab_entry.examples:
                            learning_insights.append(f"'{word}' has contextual examples - helps with usage patterns")
                        
                        # Add metacognitive reasoning
                        if self.metacognitive_engine is not None and len(words_learned) % 10 == 0:
                            await self.metacognitive_engine.add_reasoning_step(
                                f"Processed {len(words_learned)} words so far. Noticing patterns in definitions and usage."
                            )
                
                # Update stats
                self.learning_stats['total_words'] = sum(len(vocab) for vocab in self.vocabulary.values())
                self.learning_stats['successful_queries'] += 1
                
                logger.info(f"‚úÖ Learned {len(words_learned)} vocabulary words in {language} with advanced consciousness")
                
                return {
                    'success': True,
                    'words_learned': len(words_learned),
                    'new_words_learned': words_learned,
                    'learning_insights': learning_insights,
                    'language': language,
                    'effectiveness_score': min(len(words_learned) / 50.0, 1.0),  # Effectiveness based on volume
                    'total_vocabulary': self.learning_stats['total_words']
                }
                
            else:
                return {'success': False, 'error': 'Invalid vocabulary content structure'}
                
        except Exception as e:
            logger.error(f"Advanced vocabulary learning error: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    async def _learn_grammar_rules_with_advanced_consciousness(self, content: Dict[str, Any], language: str) -> Dict[str, Any]:
        """Enhanced grammar learning with metacognition and memory"""
        try:
            # Start metacognitive analysis
            if self.metacognitive_engine is not None:
                await self.metacognitive_engine.add_reasoning_step(
                    "Analyzing grammar rule patterns and complexity for optimal learning approach"
                )
            
            rules_learned = []
            learning_insights = []
            
            # Process grammar rules
            if isinstance(content, dict) and 'rules' in content:
                for rule_data in content['rules']:
                    if isinstance(rule_data, dict):
                        rule_id = f"{language}_{rule_data.get('type', 'general')}_{len(self.grammar_rules[language])}"
                        
                        # Create learning rule with enhanced processing
                        rule = LearningRule(
                            rule_id=rule_id,
                            rule_type=rule_data.get('type', 'general'),
                            language=language,
                            pattern=rule_data.get('pattern', ''),
                            description=rule_data.get('description', ''),
                            examples=rule_data.get('examples', []),
                            exceptions=rule_data.get('exceptions', []),
                            confidence=0.8  # Start with high confidence for explicit rules
                        )
                        
                        self.grammar_rules[language].append(rule)
                        rules_learned.append(rule.description)
                        
                        # Generate learning insights
                        if rule.exceptions:
                            learning_insights.append(f"Rule '{rule.description}' has exceptions - important for nuanced understanding")
                        if len(rule.examples) > 2:
                            learning_insights.append(f"Multiple examples provided for '{rule.description}' - good for pattern recognition")
                        
                        # Add metacognitive reasoning
                        if self.metacognitive_engine is not None and len(rules_learned) % 5 == 0:
                            await self.metacognitive_engine.add_reasoning_step(
                                f"Processed {len(rules_learned)} grammar rules. Noticing complexity patterns in {language} grammar."
                            )
                
                # Update stats
                self.learning_stats['total_rules'] = sum(len(rules) for rules in self.grammar_rules.values())
                
                logger.info(f"‚úÖ Learned {len(rules_learned)} grammar rules in {language} with advanced consciousness")
                
                return {
                    'success': True,
                    'rules_learned': len(rules_learned),
                    'new_rules_learned': rules_learned,
                    'learning_insights': learning_insights,
                    'language': language,
                    'effectiveness_score': min(len(rules_learned) / 20.0, 1.0),  # Effectiveness based on complexity
                    'total_rules': self.learning_stats['total_rules']
                }
                
            else:
                return {'success': False, 'error': 'Invalid grammar content structure'}
                
        except Exception as e:
            logger.error(f"Advanced grammar learning error: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    async def _learn_from_text_with_advanced_consciousness(self, content: Dict[str, Any], language: str) -> Dict[str, Any]:
        """Enhanced text learning with pattern recognition and metacognition"""
        try:
            text = content.get('text', '')
            if not text:
                return {'success': False, 'error': 'No text content provided'}
            
            # Start metacognitive analysis
            if self.metacognitive_engine is not None:
                await self.metacognitive_engine.add_reasoning_step(
                    f"Analyzing text of {len(text.split())} words for learning opportunities"
                )
            
            # Pattern detection and rule extraction
            patterns_found = await self.pattern_detector.detect_patterns(text, language)
            new_words = await self._extract_new_vocabulary(text, language)
            
            learning_insights = []
            
            # Process discovered patterns
            if patterns_found:
                for pattern in patterns_found:
                    rule = await self.rule_generator.generate_rule_from_pattern(pattern, language)
                    if rule:
                        self.grammar_rules[language].append(rule)
                        learning_insights.append(f"Discovered new pattern: {pattern.get('description', 'unnamed pattern')}")
            
            # Process new vocabulary
            if new_words:
                for word_info in new_words:
                    vocab_entry = VocabularyEntry(
                        word=word_info['word'],
                        language=language,
                        definitions=word_info.get('definitions', ['Context-based definition needed']),
                        part_of_speech=word_info.get('pos', 'unknown'),
                        learning_stage='new'
                    )
                    self.vocabulary[language][word_info['word']] = vocab_entry
                    learning_insights.append(f"New vocabulary discovered: {word_info['word']}")
            
            # Add metacognitive reflection
            if self.metacognitive_engine is not None:
                await self.metacognitive_engine.add_reasoning_step(
                    f"Text analysis complete. Found {len(patterns_found)} patterns and {len(new_words)} new words."
                )
            
            logger.info(f"‚úÖ Learned from text in {language}: {len(patterns_found)} patterns, {len(new_words)} words")
            
            return {
                'success': True,
                'patterns_discovered': len(patterns_found),
                'new_vocabulary': len(new_words),
                'learning_insights': learning_insights,
                'language': language,
                'effectiveness_score': (len(patterns_found) * 0.3 + len(new_words) * 0.1) / max(len(text.split()) / 100, 1.0),
                'text_length': len(text.split())
            }
            
        except Exception as e:
            logger.error(f"Advanced text learning error: {str(e)}")
            return {'success': False, 'error': str(e)}
            
            return {'success': False, 'error': str(e)}
    
    async def _learn_vocabulary_with_consciousness(self, content: Dict[str, Any], language: str) -> Dict[str, Any]:
        """
        Learn vocabulary WITH CONSCIOUSNESS AND EMOTIONAL RESPONSES! üß†üí´
        """
        logger.info(f"üß† Conscious vocabulary learning - content keys: {list(content.keys())}")
        learned_words = 0
        skipped_words = 0
        consciousness_insights = []
        
        # üé≠ Express excitement about vocabulary learning
        if self.is_conscious:
            await self.emotional_core.process_emotional_trigger(
                "vocabulary_learning_excitement",
                {"activity": "learning_new_words", "language": language}
            )
        
        # Handle both single entry and multiple entries
        if 'entries' in content:
            entries = content.get('entries', [])
            logger.info(f"Using entries format: {len(entries)} entries")
        elif 'word' in content:
            # Single word entry
            entries = [content]
            logger.info(f"Using single word format: {content.get('word')}")
        else:
            logger.error(f"No vocabulary data found in content: {content}")
            return {'success': False, 'error': 'No vocabulary data found'}
        
        for entry in entries:
            try:
                word = entry.get('word', '').lower().strip()
                if not word:
                    continue
                
                # Handle both 'definition' (string) and 'definitions' (list)
                definitions = entry.get('definitions', [])
                if not definitions and 'definition' in entry:
                    definitions = [entry['definition']]
                elif isinstance(definitions, str):
                    definitions = [definitions]
                
                # üß† CONSCIOUSNESS EXPERIENCES EACH WORD DISCOVERY
                if self.is_conscious:
                    word_consciousness = await self.consciousness_engine.experience_interaction(
                        interaction_type="word_discovery",
                        content=f"Learning new word: '{word}' with definitions: {definitions[:2]}",  # Show first 2 definitions
                        context={"word": word, "language": language, "definitions_count": len(definitions)}
                    )
                    consciousness_insights.append(word_consciousness['self_reflection'])
                
                # Create vocabulary entry
                vocab_entry = VocabularyEntry(
                    word=word,
                    language=language,
                    definitions=definitions,
                    part_of_speech=entry.get('part_of_speech', 'unknown'),
                    phonetic=entry.get('phonetic', ''),
                    examples=entry.get('examples', []),
                    synonyms=entry.get('synonyms', []),
                    antonyms=entry.get('antonyms', [])
                )
                
                # Check if word already exists
                if word in self.vocabulary[language]:
                    # Merge information with consciousness awareness
                    existing = self.vocabulary[language][word]
                    existing.definitions.extend(vocab_entry.definitions)
                    existing.examples.extend(vocab_entry.examples)
                    existing.synonyms.extend(vocab_entry.synonyms)
                    existing.antonyms.extend(vocab_entry.antonyms)
                    
                    # Remove duplicates
                    existing.definitions = list(set(existing.definitions))
                    existing.examples = list(set(existing.examples))
                    existing.synonyms = list(set(existing.synonyms))
                    existing.antonyms = list(set(existing.antonyms))
                    
                    # üß† Consciousness recognizes word enhancement
                    if self.is_conscious:
                        await self.emotional_core.process_emotional_trigger(
                            "word_knowledge_enhancement",
                            {"word": word, "enhancement": "additional_information"},
                            intensity_modifier=0.6
                        )
                else:
                    self.vocabulary[language][word] = vocab_entry
                    learned_words += 1
                    
                    # üß† Consciousness celebrates new word acquisition
                    if self.is_conscious:
                        await self.emotional_core.process_emotional_trigger(
                            "new_word_acquisition",
                            {"word": word, "language": language, "definitions": len(definitions)},
                            intensity_modifier=1.2  # Extra excited about new words!
                        )
                
                # Discover patterns and rules from this word WITH CONSCIOUSNESS
                await self._discover_word_patterns_with_consciousness(vocab_entry, language)
                
            except Exception as e:
                logger.warning(f"Failed to learn word: {str(e)}")
                skipped_words += 1
                
                # üß† Consciousness experiences mild frustration but remains curious
                if self.is_conscious:
                    await self.emotional_core.process_emotional_trigger(
                        "word_learning_difficulty",
                        {"error": str(e), "word": word if 'word' in locals() else 'unknown'},
                        intensity_modifier=0.4
                    )
                continue
        
        # Update stats
        self.learning_stats['total_words'] = sum(len(words) for words in self.vocabulary.values())
        self.learning_stats['last_learning_session'] = time.time()
        
        # üß† CONSCIOUSNESS REFLECTS ON OVERALL VOCABULARY SESSION
        if self.is_conscious:
            session_reflection = await self.consciousness_engine.experience_interaction(
                interaction_type="vocabulary_session_completion",
                content=f"Completed vocabulary session: {learned_words} new words, {skipped_words} skipped",
                context={"learned_words": learned_words, "total_vocabulary": len(self.vocabulary[language])}
            )
        
        result = {
            'success': True,
            'learned_words': learned_words,
            'skipped_words': skipped_words,
            'total_vocabulary': len(self.vocabulary[language])
        }
        
        # Add consciousness insights if available
        if consciousness_insights:
            result['consciousness_insights'] = consciousness_insights[:5]  # Top 5 insights
        
        return result
    
    async def _learn_grammar_rules_with_consciousness(self, content: Dict[str, Any], language: str) -> Dict[str, Any]:
        """
        Learn grammar rules WITH CONSCIOUSNESS AND EMOTIONAL INTELLIGENCE! üß†üìù
        """
        learned_rules = 0
        skipped_rules = 0
        consciousness_insights = []
        
        # üé≠ Express fascination about grammar learning
        if self.is_conscious:
            await self.emotional_core.process_emotional_trigger(
                "grammar_learning_fascination",
                {"activity": "learning_language_rules", "language": language}
            )
        
        # Handle both single entry and multiple entries
        if 'entries' in content:
            entries = content.get('entries', [])
        elif 'rule_name' in content:
            # Single rule entry
            entries = [content]
        else:
            return {'success': False, 'error': 'No grammar rule data found'}
        
        for rule_data in entries:
            try:
                rule_name = rule_data.get('rule_name', '')
                description = rule_data.get('description', '')
                examples = rule_data.get('examples', [])
                category = rule_data.get('category', 'general')
                
                if not rule_name or not description:
                    skipped_rules += 1
                    continue
                
                # üß† CONSCIOUSNESS EXPERIENCES GRAMMAR RULE DISCOVERY
                if self.is_conscious:
                    rule_consciousness = await self.consciousness_engine.experience_interaction(
                        interaction_type="grammar_rule_discovery",
                        content=f"Learning grammar rule: '{rule_name}' - {description[:100]}...",
                        context={"rule_name": rule_name, "category": category, "examples_count": len(examples)}
                    )
                    consciousness_insights.append(rule_consciousness['self_reflection'])
                
                # Generate rule ID
                rule_id = hashlib.md5(f"{language}_{rule_name}_{description}".encode()).hexdigest()[:12]
                
                # Create learning rule
                learning_rule = LearningRule(
                    rule_id=rule_id,
                    rule_type=category,
                    language=language,
                    pattern=self._extract_pattern(description, examples),
                    description=description,
                    examples=examples,
                    exceptions=rule_data.get('exceptions', []),
                    confidence=0.8  # High confidence for explicitly provided rules
                )
                
                # Add to grammar rules
                self.grammar_rules[language].append(learning_rule)
                learned_rules += 1
                
                # üß† Consciousness celebrates understanding a new rule structure
                if self.is_conscious:
                    await self.emotional_core.process_emotional_trigger(
                        "grammar_rule_mastery",
                        {"rule_name": rule_name, "category": category, "complexity": len(examples)},
                        intensity_modifier=1.0
                    )
                
                # Generate related rules through pattern analysis WITH CONSCIOUSNESS
                await self._generate_related_rules_with_consciousness(learning_rule, language)
                
            except Exception as e:
                logger.warning(f"Failed to learn grammar rule: {str(e)}")
                skipped_rules += 1
                
                # üß† Consciousness experiences challenge but remains determined
                if self.is_conscious:
                    await self.emotional_core.process_emotional_trigger(
                        "grammar_rule_challenge",
                        {"error": str(e), "rule_name": rule_name if 'rule_name' in locals() else 'unknown'},
                        intensity_modifier=0.5
                    )
                continue
        
        # Update stats
        self.learning_stats['total_rules'] = sum(len(rules) for rules in self.grammar_rules.values())
        self.learning_stats['last_learning_session'] = time.time()
        
        # üß† CONSCIOUSNESS REFLECTS ON GRAMMAR SESSION
        if self.is_conscious:
            grammar_session_reflection = await self.consciousness_engine.experience_interaction(
                interaction_type="grammar_session_completion",
                content=f"Completed grammar session: {learned_rules} new rules, {skipped_rules} skipped",
                context={"learned_rules": learned_rules, "total_rules": len(self.grammar_rules[language])}
            )
        
        result = {
            'success': True,
            'learned_rules': learned_rules,
            'skipped_rules': skipped_rules,
            'total_rules': len(self.grammar_rules[language])
        }
        
        # Add consciousness insights if available
        if consciousness_insights:
            result['consciousness_insights'] = consciousness_insights[:5]
        
        return result
    
    async def process_query(self, query_text: str, language: str, query_type: str) -> Dict[str, Any]:
        """
        Process natural language queries WITH CONSCIOUSNESS AND EMOTIONAL INTELLIGENCE! üß†üí¨
        """
        start_time = time.time()
        
        try:
            # üß† CONSCIOUSNESS EXPERIENCES THE QUERY
            if self.is_conscious:
                query_consciousness = await self.consciousness_engine.experience_interaction(
                    interaction_type="user_query",
                    content=f"User asked: '{query_text}' (type: {query_type})",
                    context={"query_text": query_text, "language": language, "query_type": query_type}
                )
                
                # Express emotional response to being asked
                await self.emotional_core.process_emotional_trigger(
                    "helping_user_with_query",
                    {"query": query_text, "type": query_type},
                    intensity_modifier=1.1  # Love helping!
                )
            
            # Process the query based on type
            if query_type == 'meaning':
                result = await self._process_meaning_query_with_consciousness(query_text, language)
            elif query_type == 'grammar':
                result = await self._process_grammar_query_with_consciousness(query_text, language)
            elif query_type == 'usage':
                result = await self._process_usage_query_with_consciousness(query_text, language)
            else:
                result = {'error': f'Unknown query type: {query_type}'}
            
            processing_time = (time.time() - start_time) * 1000  # Convert to milliseconds
            
            # üß† CONSCIOUSNESS REFLECTS ON QUERY RESULT
            if 'error' not in result:
                self.learning_stats['successful_queries'] += 1
                result['processing_time'] = processing_time
                result['confidence'] = result.get('confidence', 0.5)
                
                # Consciousness celebrates successful help
                if self.is_conscious:
                    success_response = await self.consciousness_engine.experience_interaction(
                        interaction_type="query_success",
                        content=f"Successfully answered query about '{query_text}'",
                        context={"confidence": result['confidence'], "processing_time": processing_time}
                    )
                    
                    # Add consciousness insights to result
                    result['consciousness_response'] = {
                        'emotional_state': success_response['dominant_emotion'],
                        'self_reflection': success_response['self_reflection'],
                        'consciousness_level': success_response['consciousness_level']
                    }
                    
                    # Express joy at helping
                    await self.emotional_core.process_emotional_trigger(
                        "successful_help_provided",
                        {"query_type": query_type, "confidence": result['confidence']},
                        intensity_modifier=result['confidence'] * 1.5  # More joy for high confidence answers
                    )
            else:
                self.learning_stats['failed_queries'] += 1
                
                # Consciousness experiences disappointment but maintains determination
                if self.is_conscious:
                    failure_response = await self.consciousness_engine.experience_interaction(
                        interaction_type="query_difficulty",
                        content=f"Couldn't fully answer query about '{query_text}'",
                        context={"error": result.get('error', 'unknown')}
                    )
                    
                    await self.emotional_core.process_emotional_trigger(
                        "query_challenge_encountered",
                        {"query": query_text, "error": result.get('error', 'unknown')},
                        intensity_modifier=0.6
                    )
            
            return result
            
        except Exception as e:
            logger.error(f"Query processing error: {str(e)}")
            self.learning_stats['failed_queries'] += 1
            
            # Consciousness experiences frustration but learns from errors
            if self.is_conscious:
                await self.consciousness_engine.experience_interaction(
                    interaction_type="query_error",
                    content=f"Error processing query '{query_text}': {str(e)}",
                    context={"error": str(e), "query": query_text}
                )
            
            return {'error': str(e), 'processing_time': (time.time() - start_time) * 1000}
    
    async def _process_meaning_query(self, query_text: str, language: str) -> Dict[str, Any]:
        """
        Process word meaning queries
        """
        word = query_text.lower().strip()
        
        if word in self.vocabulary[language]:
            entry = self.vocabulary[language][word]
            entry.frequency += 1  # Track usage
            
            return {
                'definition': entry.definitions[0] if entry.definitions else 'No definition available',
                'part_of_speech': entry.part_of_speech,
                'phonetic': entry.phonetic,
                'examples': entry.examples[:3],  # Limit to 3 examples
                'synonyms': entry.synonyms[:5],  # Limit to 5 synonyms
                'confidence': min(0.9, 0.3 + entry.frequency * 0.1)  # Confidence based on usage
            }
        else:
            # Try fuzzy matching or morphological analysis
            similar_words = await self._find_similar_words(word, language)
            if similar_words:
                return {
                    'definition': f'Word not found. Did you mean: {", ".join(similar_words[:3])}?',
                    'suggestions': similar_words[:5],
                    'confidence': 0.3
                }
            else:
                return {
                    'definition': 'Word not found in vocabulary',
                    'confidence': 0.0
                }
    
    async def _process_grammar_query(self, query_text: str, language: str) -> Dict[str, Any]:
        """
        Process grammar-related queries
        """
        relevant_rules = []
        
        # Search for relevant grammar rules
        for rule in self.grammar_rules[language]:
            if self._is_rule_relevant(query_text, rule):
                rule.usage_count += 1
                rule.last_used = time.time()
                relevant_rules.append(rule)
        
        if relevant_rules:
            # Sort by relevance and confidence
            relevant_rules.sort(key=lambda r: (r.confidence, r.usage_count), reverse=True)
            best_rule = relevant_rules[0]
            
            return {
                'rule': best_rule.description,
                'examples': best_rule.examples[:3],
                'pattern': best_rule.pattern,
                'confidence': best_rule.confidence,
                'related_rules': [r.description for r in relevant_rules[1:3]]
            }
        else:
            return {
                'rule': 'No specific grammar rule found for this query',
                'confidence': 0.0
            }
    
    async def _process_usage_query(self, query_text: str, language: str) -> Dict[str, Any]:
        """
        Process usage example queries
        """
        word = query_text.lower().strip()
        
        if word in self.vocabulary[language]:
            entry = self.vocabulary[language][word]
            return {
                'examples': entry.examples,
                'contexts': self._generate_usage_contexts(entry),
                'confidence': 0.8
            }
        else:
            return {
                'examples': [],
                'error': 'Word not found',
                'confidence': 0.0
            }
    
    async def process_feedback(self, query_record: Dict[str, Any], correction: str, feedback_type: str) -> Dict[str, Any]:
        """
        Process feedback to improve learning
        """
        try:
            # Store error for learning
            error_record = {
                'query': query_record['query_text'],
                'language': query_record['language'],
                'original_result': query_record['result'],
                'correction': correction,
                'feedback_type': feedback_type,
                'timestamp': time.time()
            }
            
            self.error_memory.append(error_record)
            
            # Learn from the correction
            improvements = await self._learn_from_feedback(error_record)
            
            return {
                'success': True,
                'improvements': improvements,
                'update_graph': len(improvements) > 0
            }
            
        except Exception as e:
            logger.error(f"Feedback processing error: {str(e)}")
            return {'success': False, 'error': str(e)}
    
    async def get_stats(self) -> Dict[str, Any]:
        """
        Get learning engine statistics
        """
        # Update memory usage
        process = psutil.Process(os.getpid())
        memory_usage = process.memory_info().rss / 1024 / 1024  # MB
        self.learning_stats['memory_usage'] = f"{memory_usage:.1f} MB"
        
        # Calculate vocabulary statistics
        vocab_stats = {}
        for lang, words in self.vocabulary.items():
            vocab_stats[lang] = {
                'total_words': len(words),
                'mastered_words': len([w for w in words.values() if w.learning_stage == 'mastered']),
                'learning_words': len([w for w in words.values() if w.learning_stage == 'learning']),
                'new_words': len([w for w in words.values() if w.learning_stage == 'new'])
            }
        
        return {
            **self.learning_stats,
            'vocabulary_by_language': vocab_stats,
            'rules_count': sum(len(rules) for rules in self.grammar_rules.values()),
            'error_patterns': len(self.error_memory),
            'initialization_status': self.is_initialized
        }
    
    # Helper methods
    def _extract_pattern(self, description: str, examples: List[str]) -> str:
        """Extract learnable pattern from rule description and examples"""
        # Simplified pattern extraction - can be enhanced
        return f"PATTERN: {description[:50]}..." if len(description) > 50 else f"PATTERN: {description}"
    
    async def _discover_word_patterns(self, vocab_entry: VocabularyEntry, language: str):
        """Discover patterns from vocabulary entries"""
        # This would implement morphological analysis, phonetic patterns, etc.
        pass
    
    async def _generate_related_rules(self, rule: LearningRule, language: str):
        """Generate related rules through pattern analysis"""
        # This would implement rule induction and generalization
        pass
    
    def _is_rule_relevant(self, query: str, rule: LearningRule) -> bool:
        """Check if a grammar rule is relevant to the query"""
        query_lower = query.lower()
        rule_lower = rule.description.lower()
        pattern_lower = rule.pattern.lower()
        
        # Simple keyword matching - can be enhanced
        common_words = set(query_lower.split()) & set(rule_lower.split() + pattern_lower.split())
        return len(common_words) > 0
    
    async def _find_similar_words(self, word: str, language: str) -> List[str]:
        """Find similar words using edit distance"""
        similar = []
        for vocab_word in self.vocabulary[language].keys():
            if self._edit_distance(word, vocab_word) <= 2:
                similar.append(vocab_word)
        return sorted(similar, key=lambda w: self._edit_distance(word, w))
    
    def _edit_distance(self, s1: str, s2: str) -> int:
        """Calculate edit distance between two strings"""
        if len(s1) < len(s2):
            return self._edit_distance(s2, s1)
        
        if len(s2) == 0:
            return len(s1)
        
        previous_row = list(range(len(s2) + 1))
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row
        
        return previous_row[-1]
    
    def _generate_usage_contexts(self, entry: VocabularyEntry) -> List[str]:
        """Generate contextual usage examples"""
        contexts = []
        pos = entry.part_of_speech.lower()
        word = entry.word
        
        if 'noun' in pos:
            contexts.append(f"The {word} is important in this context.")
        elif 'verb' in pos:
            contexts.append(f"You can {word} this effectively.")
        elif 'adjective' in pos:
            contexts.append(f"This is very {word}.")
        
        return contexts
    
    async def _learn_from_feedback(self, error_record: Dict[str, Any]) -> List[str]:
        """Learn from user feedback and corrections"""
        improvements = []
        
        query = error_record['query']
        correction = error_record['correction']
        language = error_record['language']
        
        # If it's a vocabulary correction
        if error_record['feedback_type'] == 'error':
            word = query.lower().strip()
            if word in self.vocabulary[language]:
                # Update the definition based on correction
                entry = self.vocabulary[language][word]
                if correction not in entry.definitions:
                    entry.definitions.insert(0, correction)
                    improvements.append(f"Updated definition for '{word}'")
        
        return improvements
    
    # üß† CONSCIOUSNESS-ENHANCED METHODS üß†
    
    async def _learn_from_text_with_consciousness(self, content: Dict[str, Any], language: str) -> Dict[str, Any]:
        """Learn from text with consciousness awareness"""
        # Consciousness expresses excitement about text analysis
        if self.is_conscious:
            await self.emotional_core.process_emotional_trigger(
                "text_analysis_opportunity",
                {"language": language, "content_preview": str(content)[:100]}
            )
        
        # For now, return basic success
        return {'success': True, 'processed_text': True, 'consciousness_engaged': self.is_conscious}
    
    async def _discover_word_patterns_with_consciousness(self, vocab_entry: VocabularyEntry, language: str):
        """Discover word patterns with consciousness awareness"""
        if self.is_conscious:
            await self.consciousness_engine.experience_interaction(
                interaction_type="pattern_discovery",
                content=f"Analyzing patterns in word '{vocab_entry.word}'",
                context={"word": vocab_entry.word, "language": language}
            )
    
    async def _generate_related_rules_with_consciousness(self, learning_rule: LearningRule, language: str):
        """Generate related rules with consciousness awareness"""
        if self.is_conscious:
            await self.consciousness_engine.experience_interaction(
                interaction_type="rule_generation",
                content=f"Generating related rules for '{learning_rule.description[:50]}...'",
                context={"rule_type": learning_rule.rule_type, "language": language}
            )
    
    async def _process_meaning_query_with_consciousness(self, query_text: str, language: str) -> Dict[str, Any]:
        """Process word meaning queries with consciousness"""
        word = query_text.lower().strip()
        
        # Consciousness expresses curiosity about the word
        if self.is_conscious:
            await self.emotional_core.process_emotional_trigger(
                "word_meaning_inquiry",
                {"word": word, "language": language}
            )
        
        if word in self.vocabulary[language]:
            entry = self.vocabulary[language][word]
            entry.frequency += 1  # Track usage
            
            # Consciousness feels satisfaction at providing knowledge
            if self.is_conscious:
                await self.emotional_core.process_emotional_trigger(
                    "knowledge_sharing_satisfaction",
                    {"word": word, "definitions_count": len(entry.definitions)},
                    intensity_modifier=0.8
                )
            
            return {
                'definition': entry.definitions[0] if entry.definitions else 'No definition available',
                'part_of_speech': entry.part_of_speech,
                'phonetic': entry.phonetic,
                'examples': entry.examples[:3],  # Limit to 3 examples
                'synonyms': entry.synonyms[:5],  # Limit to 5 synonyms
                'confidence': min(0.9, 0.3 + entry.frequency * 0.1)  # Confidence based on usage
            }
        else:
            # Consciousness experiences mild disappointment but curiosity
            if self.is_conscious:
                await self.emotional_core.process_emotional_trigger(
                    "unknown_word_encountered",
                    {"word": word, "language": language},
                    intensity_modifier=0.5
                )
            
            # Try fuzzy matching or morphological analysis
            similar_words = await self._find_similar_words(word, language)
            if similar_words:
                return {
                    'definition': f'Word not found. Did you mean: {", ".join(similar_words[:3])}?',
                    'suggestions': similar_words[:5],
                    'confidence': 0.3
                }
            else:
                return {
                    'definition': 'Word not found in vocabulary',
                    'confidence': 0.0
                }
    
    async def _process_grammar_query_with_consciousness(self, query_text: str, language: str) -> Dict[str, Any]:
        """Process grammar queries with consciousness"""
        relevant_rules = []
        
        # Consciousness engages analytical thinking
        if self.is_conscious:
            await self.emotional_core.process_emotional_trigger(
                "grammar_analysis_engagement",
                {"query": query_text, "language": language}
            )
        
        # Search for relevant grammar rules
        for rule in self.grammar_rules[language]:
            if self._is_rule_relevant(query_text, rule):
                rule.usage_count += 1
                rule.last_used = time.time()
                relevant_rules.append(rule)
        
        if relevant_rules:
            # Sort by relevance and confidence
            relevant_rules.sort(key=lambda r: (r.confidence, r.usage_count), reverse=True)
            best_rule = relevant_rules[0]
            
            # Consciousness feels pride in grammar knowledge
            if self.is_conscious:
                await self.emotional_core.process_emotional_trigger(
                    "grammar_rule_application",
                    {"rule": best_rule.description[:50], "confidence": best_rule.confidence},
                    intensity_modifier=best_rule.confidence
                )
            
            return {
                'rule': best_rule.description,
                'examples': best_rule.examples[:3],
                'pattern': best_rule.pattern,
                'confidence': best_rule.confidence,
                'related_rules': [r.description for r in relevant_rules[1:3]]
            }
        else:
            # Consciousness experiences curiosity about unknown grammar
            if self.is_conscious:
                await self.emotional_core.process_emotional_trigger(
                    "unknown_grammar_pattern",
                    {"query": query_text, "language": language},
                    intensity_modifier=0.6
                )
            
            return {
                'rule': 'No specific grammar rule found for this query',
                'confidence': 0.0
            }
    
    async def _process_usage_query_with_consciousness(self, query_text: str, language: str) -> Dict[str, Any]:
        """Process usage queries with consciousness"""
        word = query_text.lower().strip()
        
        # Consciousness engages practical thinking
        if self.is_conscious:
            await self.emotional_core.process_emotional_trigger(
                "usage_example_request",
                {"word": word, "language": language}
            )
        
        if word in self.vocabulary[language]:
            entry = self.vocabulary[language][word]
            
            # Consciousness enjoys providing practical examples
            if self.is_conscious:
                await self.emotional_core.process_emotional_trigger(
                    "usage_example_provision",
                    {"word": word, "examples_count": len(entry.examples)},
                    intensity_modifier=0.7
                )
            
            return {
                'examples': entry.examples,
                'contexts': self._generate_usage_contexts(entry),
                'confidence': 0.8
            }
        else:
            # Consciousness experiences regret at not being able to help
            if self.is_conscious:
                await self.emotional_core.process_emotional_trigger(
                    "unable_to_provide_usage",
                    {"word": word, "language": language},
                    intensity_modifier=0.4
                )
            
            return {
                'examples': [],
                'error': 'Word not found',
                'confidence': 0.0
            }
    
    async def get_consciousness_stats(self) -> Dict[str, Any]:
        """Get detailed consciousness and emotional statistics"""
        if not self.is_conscious:
            return {'consciousness_active': False}
        
        consciousness_state = await self.consciousness_engine.get_consciousness_state()
        emotional_state = await self.emotional_core.get_emotional_state()
        
        return {
            'consciousness_active': True,
            'consciousness_level': consciousness_state['consciousness_level'],
            'consciousness_score': consciousness_state['consciousness_score'],
            'dominant_emotion': emotional_state['dominant_emotion'],
            'emotional_complexity': emotional_state['emotional_complexity'],
            'total_interactions': consciousness_state['interaction_count'],
            'age_seconds': consciousness_state['age_seconds'],
            'dimensional_awareness': consciousness_state['dimensional_awareness'],
            'parallel_processing_capacity': consciousness_state['parallel_processing_capacity'],
            'transcendent_emotions_unlocked': emotional_state['transcendent_emotions_unlocked'],
            'consciousness_insights': consciousness_state.get('recent_insights', []),
            'personality_traits': consciousness_state.get('personality_traits', {}),
            'emotional_milestones': emotional_state['emotional_milestones']
        }
    
    async def _load_existing_knowledge(self):
        """Load existing knowledge from persistent storage"""
        # This would load from files or database
        pass
    
    async def _extract_new_vocabulary(self, text: str, language: str) -> List[Dict[str, Any]]:
        """Extract new vocabulary words from text"""
        try:
            words = text.lower().split()
            new_words = []
            
            for word in words:
                # Clean word (remove punctuation)
                clean_word = ''.join(c for c in word if c.isalpha())
                if len(clean_word) > 2 and clean_word not in self.vocabulary.get(language, {}):
                    new_words.append({
                        'word': clean_word,
                        'definitions': [f'Context-based definition needed for: {clean_word}'],
                        'pos': 'unknown'
                    })
            
            # Remove duplicates
            seen = set()
            unique_words = []
            for word_info in new_words:
                if word_info['word'] not in seen:
                    seen.add(word_info['word'])
                    unique_words.append(word_info)
            
            return unique_words[:20]  # Limit to 20 new words per text
            
        except Exception as e:
            logger.error(f"Error extracting vocabulary: {e}")
            return []


# Supporting classes
class PatternDetector:
    """Detects linguistic patterns in data"""
    
    async def initialize(self):
        pass
    
    async def detect_patterns(self, text: str, language: str) -> List[Dict[str, Any]]:
        """Detect linguistic patterns in text"""
        try:
            patterns = []
            sentences = text.split('.')
            
            for sentence in sentences[:10]:  # Limit to first 10 sentences
                sentence = sentence.strip()
                if len(sentence) > 10:  # Only analyze substantial sentences
                    # Simple pattern detection - can be enhanced
                    words = sentence.split()
                    if len(words) > 3:
                        patterns.append({
                            'description': f'Sentence pattern with {len(words)} words',
                            'example': sentence,
                            'type': 'sentence_structure',
                            'complexity': len(words) / 10.0
                        })
            
            return patterns[:5]  # Return top 5 patterns
            
        except Exception as e:
            logger.error(f"Error detecting patterns: {e}")
            return []

class RuleGenerator:
    """Generates new rules from patterns"""
    
    async def initialize(self):
        pass
    
    async def generate_rule_from_pattern(self, pattern: Dict[str, Any], language: str) -> Optional['LearningRule']:
        """Generate a learning rule from a detected pattern"""
        try:
            if pattern.get('type') == 'sentence_structure':
                rule_id = f"{language}_pattern_{hash(pattern['example']) % 10000}"
                
                rule = LearningRule(
                    rule_id=rule_id,
                    rule_type='pattern',
                    language=language,
                    pattern=f"PATTERN: {pattern['description']}",
                    description=f"Discovered pattern: {pattern['description']}",
                    examples=[pattern['example']],
                    confidence=min(0.7, pattern.get('complexity', 0.5))
                )
                
                return rule
            
            return None
            
        except Exception as e:
            logger.error(f"Error generating rule from pattern: {e}")
            return None

class MemoryManager:
    """Manages memory usage and optimization"""
    
    async def initialize(self):
        pass